{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the GSFLOW model\n",
    "\n",
    "So far, two models, watershed model and groundwater model, are generated but are not connected. In this notebook, we will demonstrate how these two model can be connected to form the GSFLOW model. Note: To successfully run this exercise make sure to provide the correct paths for the PRMS folder and MODFLOW folder.\n",
    "\n",
    "### Outline\n",
    "* Assemble GSFLOW model from PRMS and MODFLOW\n",
    "* Run the model and visualize the ouputs.\n",
    "\n",
    "\n",
    "<img src = \".\\figures\\WorkFlow.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.10'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from gsflow import GsflowModel\n",
    "import flopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "flopy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Load the PRMS model using pyGSFLOW\n",
    "Notice that loaded control file has a \"PRMS\" mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control file is loaded\n",
      "Working on loading PRMS model ...\n",
      "Prms model loading ...\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "Warning: data type will be infered from data supplied\n",
      "PRMS model loaded ...\n",
      "Mode is set to PRMS only, loading PRMS model only\n"
     ]
    }
   ],
   "source": [
    "control_file = r\"./data/sagehen/prms/windows/sagehen.control\"\n",
    "gs = GsflowModel.load_from_file(control_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Load Modflow using pygsflow\n",
    "\n",
    "pygsflow has a special module that loads Modflow models using FloPy, but corrects for loading and file writing issues specific to GSFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loading iuzfbnd array...\n",
      "   loading irunbnd array...\n",
      "   loading vks array...\n",
      "   loading eps array...\n",
      "   loading thts array...\n",
      "stress period 1:\n",
      "   loading finf array...\n",
      "stress period 2:\n"
     ]
    }
   ],
   "source": [
    "from gsflow.modflow import Modflow\n",
    "\n",
    "mf = Modflow.load(r\"./data/sagehen/modflow/saghen.nam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Add Modflow object to pyGSFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DIS', 'BAS6', 'UPW', 'SFR', 'OC', 'UZF', 'NWT']\n"
     ]
    }
   ],
   "source": [
    "print(mf.get_package_list())\n",
    "gs.mf = mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Change model mode and  synchronize PRMS and MODFLOW times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jlarsen\\desktop\\usgs-pygsflow\\trunk\\gsflow\\param_base.py:114: UserWarning: The record does not exist modflow_time_zero\n",
      "  warnings.warn(err, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "gs.control.set_values(name=\"model_mode\", values=['GSFLOW'])\n",
    "gs.control.set_values(name=\"start_time\", values=[1982, 8, 1, 0, 0, 0])\n",
    "gs.control.set_values(name='end_time', values=[1997, 3, 31, 0, 0, 0])\n",
    "gs.control.set_values(name='modflow_time_zero', values=[1982, 8, 1, 0, 0, 0])\n",
    "gs.control.set_values(name='print_debug', values = [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Generate GSFLOW input files in the desired workspace.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the project files .....\n",
      "\n",
      "changing model workspace...\n",
      "   C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\examples\\data\\temp\n",
      "Control file is written...\n",
      "Parameters files are written...\n",
      "Data file is written...\n",
      "Modflow files are written...\n"
     ]
    }
   ],
   "source": [
    "gs.write_input(workspace=r\"./data/temp\", basename='saghen_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.gsflow_exe = os.path.abspath(r\"../bin/gsflow.exe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running GSFLOW will take about 5 minutes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyGSFLOW is using the following executable to run the model: C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\bin\\gsflow.exe\n",
      "\n",
      "(base) C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\examples\\data\\temp>C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\bin\\gsflow.exe C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\examples\\data\\temp\\saghen_new_cont.control \n",
      "\n",
      "\n",
      "                          U.S. Geological Survey\n",
      "        Coupled Groundwater and Surface-water FLOW model (GSFLOW)\n",
      "                         Version 1.2.2 02/23/2018\n",
      "\n",
      "    An integration of the Precipitation-Runoff Modeling System (PRMS)\n",
      "    and the Modular Groundwater Model (MODFLOW-NWT and MODFLOW-2005)\n",
      "\n",
      "\n",
      "                               MODFLOW-NWT \n",
      "  U.S. GEOLOGICAL SURVEY MODULAR FINITE-DIFFERENCE GROUNDWATER-FLOW MODEL\n",
      "                         WITH NEWTON FORMULATION\n",
      "                         VERSION 1.1.3, 8/01/2017 \n",
      "              BASED ON MODFLOW-2005 VERSION 1.11.0 08/08/2013\n",
      "\n",
      " WARNING, map_results requested with nmapOutVars equal 0\n",
      " no map_results output is produced\n",
      "\n",
      "WARNING, modflow_time_zero not specified, set to start_time\n",
      "\n",
      "Steady state simulation successful, used:    47 iterations\n",
      "\n",
      "Simulation time period: 1982/08/01 - 1997/03/31\n",
      "\n",
      "====================================================================\n",
      "\n",
      "\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2019/02/19 12:07:59\n",
      " Elapsed run time:  5 Minutes, 48.932 Seconds\n",
      "\n",
      " Number of time steps:   5357;  Number of non-convergence:   0\n",
      " MF iterations:          7992;  SZ iterations:            7992\n",
      " Average MF iterations:  1.49;  Average SZ iterations:    1.49\n",
      " Maximum MF iterations:    15;  Maximum SZ iterations:      15\n",
      "\n",
      "  Normal termination of simulation\n",
      "\n",
      "\n",
      "WARNING: parameter_check_flag is duplicated in the control file C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\examples\\data\\temp\\saghen_new_cont.control.\n",
      "\n",
      "\n",
      "\n",
      "WARNING: print_debug is duplicated in the control file C:\\Users\\jlarsen\\Desktop\\usgs-pygsflow\\trunk\\examples\\data\\temp\\saghen_new_cont.control.\n",
      "\n",
      "\n",
      "WARNING: dimension 'nlake_hrus' is not required; file is saghen_new_par_0.params; line number 38\n",
      "\n",
      "WARNING: parameter 'gwflow_coef' is not required; file is saghen_new_par_0.params; line number 6624\n",
      "\n",
      "WARNING: parameter 'hru_tlaps' is not required; file is saghen_new_par_0.params; line number 19579\n",
      "\n",
      "WARNING: parameter 'gw_down_id' is not required; file is saghen_new_par_1.params; line number 6498\n",
      "\n",
      "WARNING: parameter 'gw_pct_up' is not required; file is saghen_new_par_1.params; line number 18682\n",
      "\n",
      "WARNING: parameter 'gw_strmseg_down_id' is not required; file is saghen_new_par_1.params; line number 30866\n",
      "\n",
      "WARNING: parameter 'gw_up_id' is not required; file is saghen_new_par_1.params; line number 43050\n",
      "\n",
      "WARNING: parameter 'gwsink_coef' is not required; file is saghen_new_par_2.params; line number 102\n",
      "\n",
      "WARNING: parameter 'gwstor_init' is not required; file is saghen_new_par_2.params; line number 109\n",
      "\n",
      "WARNING: parameter 'gwstor_min' is not required; file is saghen_new_par_2.params; line number 116\n",
      "\n",
      "WARNING: parameter 'mapvars_freq' is not required; file is saghen_new_par_2.params; line number 137\n",
      "\n",
      "WARNING: parameter 'mapvars_units' is not required; file is saghen_new_par_2.params; line number 144\n",
      "\n",
      "WARNING: parameter 'outlet_sta' is not required; file is saghen_new_par_2.params; line number 172\n",
      "\n",
      "WARNING: parameter 'print_freq' is not required; file is saghen_new_par_2.params; line number 211\n",
      "\n",
      "WARNING: parameter 'print_type' is not required; file is saghen_new_par_2.params; line number 218\n",
      "\n",
      "WARNING: parameter 'prms_warmup' is not required; file is saghen_new_par_2.params; line number 225\n",
      "\n",
      "WARNING: parameter 'lake_hru_id' is not required; file is saghen_new_par_3.params; line number 71217\n",
      "\n",
      "WARNING: parameter mxsziter is used by module gsflow_prms but values are not\n",
      "         set in the Parameter File. Module default values are being used.\n",
      "\n",
      "WARNING: parameter snowpack_init is used by module snowcomp but values are not\n",
      "         set in the Parameter File. Module default values are being used.\n",
      "\n",
      "WARNING: parameter id_obsrunoff is used by module gsflow_sum but values are not\n",
      "         set in the Parameter File. Module default values are being used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization\n",
    "\n",
    "* GSFLOW budget: Dailey flow rates from/to all the integrated hydrologic model compartments. \n",
    "* PRMS output: PRMS Water-Budget, Statistic Variables, and PRMS Animation Variables. \n",
    "* Modflow outputs (heads & budget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSFLOW basin budget. \n",
    "GSFLOW saves the dialey flow rates (and volumes) for all the integrated hydrologic model compartments. The results are saved in a Comma-separated values (CSV) file, which can efficiently imported and visualized using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'saghen_new_csv_output.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1525ef32cbbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Import results into Pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbasin_bd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Show the first 10 lines of the budget in the notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'saghen_new_csv_output.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# The filename can be found in the control object under the name \"csv_output_file\"\n",
    "csv_file = gs.control.get_values(\"csv_output_file\")[0]\n",
    "\n",
    "# Import results into Pandas\n",
    "basin_bd = pandas.read_csv(csv_file)\n",
    "\n",
    "# Show the first 10 lines of the budget in the notebook\n",
    "basin_bd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To demonstrate plotting a budget component, let us plot the daily recharge values\n",
    "basin_bd.plot(x='Date', y = 'RechargeUnsat2Sat_Q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the budget into Pandas allows us to access all of the powerful built in operations that come with Pandas\n",
    "\n",
    "For example, let's plot the annual precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_bd['Date'] = pandas.to_datetime(basin_bd['Date'])\n",
    "Budget_by_year = basin_bd.groupby(basin_bd.Date.dt.year).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Budget_by_year['StreamOut_Q'].plot() ; plt.title(\"Annual Stream Outflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Budget_by_month = basin_bd.groupby(basin_bd.Date.dt.month).mean()\n",
    "Budget_by_month['StreamOut_Q'].plot(); plt.title(\"Monthly Stream Outflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRMS Statistic Variables\n",
    "This following method can be used to import statVar file into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "gs.prms.get_StatVar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot all results, we can use the following method...\n",
    "gs.prms.stat.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the animation is not supported yet. In the future, a method will be added to generate vedio from animation file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODFLOW Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = gs.mf\n",
    "mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydraulic Head Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Modflow output files\n",
    "mf.output_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain heads output file name\n",
    "head_file = os.path.join(mf.model_ws, mf.output_fnames[2])\n",
    "head_file\n",
    "\n",
    "cbc = os.path.join(mf.model_ws, mf.output_fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the head into the hds object\n",
    "hds = flopy.utils.HeadFile(head_file)\n",
    "cbc = flopy.utils.CellBudgetFile(cbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the head is saved at different time points, we first need to fid these times\n",
    "print(cbc.textlist)\n",
    "fff = cbc.get_data(text=\"FLOW FRONT FACE\", full3D=True)[-1]\n",
    "frf = cbc.get_data(text=\"FLOW RIGHT FACE\", full3D=True)[-1]\n",
    "flf = cbc.get_data(text=\"FLOW LOWER FACE\", full3D=True)[-1]\n",
    "# hds.get_kstpkper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the data at any time point, \n",
    "head = hds.get_data(kstpkper= (729, 1))\n",
    "head[head<0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the head map\n",
    "plt.figure(figsize=(17,6));\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(head[0,:,:],50, cmap = 'jet');plt.gca().invert_yaxis(); plt.colorbar(); plt.title(\"Head for Layer 1\")\n",
    "plt.axis('equal')\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(head[1,:,:],50, cmap = 'jet');plt.gca().invert_yaxis(); plt.colorbar(); plt.title(\"Head for Layer 2\")\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head Cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = hds.get_data()\n",
    "levels = np.arange(1830, 2505, 10)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_title('Head Cross-section')\n",
    "modelxsect = flopy.plot.ModelCrossSection(model=mf, line={'Column': 50})\n",
    "ct = modelxsect.contour_array(head, masked_values=[999.], head=head, levels=levels)\n",
    "patches = modelxsect.plot_ibound(head=head)\n",
    "wt = modelxsect.plot_surface(head, masked_values=[999.], color='blue', lw=1)\n",
    "linecollection = modelxsect.plot_grid()\n",
    "disc = modelxsect.plot_discharge(frf, fff, flf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heads Timeseries\n",
    "Sometimes we are interested more in a head change with time at a certain point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7)); \n",
    "\n",
    "# The point should be specified as  (layer, row, column)\n",
    "point = (0,50,50)\n",
    "\n",
    "# Extract time series at this point\n",
    "h_ts = hds.get_ts(idx=point)\n",
    "plt.plot(h_ts[2:,0], h_ts[2:,1], 'b', label = \"Layer 1\")\n",
    "\n",
    "\n",
    "# let us do the same thing for the second layer and compare the results ...\n",
    "point = (1,50,50)\n",
    "h_ts = hds.get_ts(idx=point)\n",
    "plt.plot(h_ts[2:,0], h_ts[2:,1], 'r', label = \"Layer 2\")\n",
    "plt.xlabel(\"Time (Days)\")\n",
    "plt.ylabel(\"Heads (m)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modflow Budget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain heads output file name\n",
    "cbc_file = os.path.join(mf.model_ws, mf.output_fnames[0])\n",
    "cbc_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Budget\n",
    "cbc = flopy.utils.CellBudgetFile(cbc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the time points where budget result is available\n",
    "cbc.get_kstpkper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list budget items that exist in the budget file\n",
    "cbc.textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot \n",
    "plt.figure(figsize=(15,10)); \n",
    "frf = cbc.get_data(full3D=True, kstpkper= (5355, 1),text='FLOW RIGHT FACE ')\n",
    "plt.subplot(2,2,1)\n",
    "plt.contourf(frf[0][0,:,:]);plt.gca().invert_yaxis(); plt.colorbar()\n",
    "plt.title('FLOW RIGHT FACE ')\n",
    "\n",
    "fff = cbc.get_data(full3D=True, kstpkper= (5355, 1),text= 'FLOW FRONT FACE ')\n",
    "plt.subplot(2,2,2)\n",
    "plt.contourf(fff[0][0,:,:]);plt.gca().invert_yaxis(); plt.colorbar()\n",
    "plt.title('FLOW FRONT FACE ')\n",
    "\n",
    "\n",
    "flf = cbc.get_data(full3D=True, kstpkper= (5355, 1),text= 'FLOW LOWER FACE ')\n",
    "plt.subplot(2,2,3)\n",
    "plt.contourf(flf[0][0,:,:]);plt.gca().invert_yaxis(); plt.colorbar()\n",
    "plt.title('FLOW LOWER FACE ')\n",
    "\n",
    "\n",
    "xx = cbc.get_data(full3D=True, kstpkper= (5355, 1),text=   '  STREAM LEAKAGE' )\n",
    "plt.subplot(2,2,4)\n",
    "plt.contourf(xx[0][0,:,:]);plt.gca().invert_yaxis(); plt.colorbar()\n",
    "plt.title('  STREAM LEAKAGE')\n",
    "plt.show()\n",
    "\n",
    "mm = flopy.plot.ModelMap(model=mf, layer=0)\n",
    "mm.plot_discharge(frf[0], flf[0], istep=1, jstep=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading information from the list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = mf.name + \".list\"\n",
    "list_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_list = flopy.utils.MfListBudget(list_file)\n",
    "incrementaldf, cumulativedf = mf_list.get_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementaldf['STORAGE_IN'].plot(label = 'Storage_in')\n",
    "incrementaldf['STORAGE_OUT'].plot(label = 'Storage_out')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementaldf['IN-OUT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script Assemble_GSFLOW_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
